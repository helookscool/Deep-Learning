{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝의 현실적인 부분\n",
    "### ML 애플리케이션 설정 : 훈련/개발/테스트 세트\n",
    "\n",
    "ML 적용은 매우 반복적인 프로세스입니다.\n",
    "<img src=\"./images/ML_process.png\" width=\"250\" align=\"right\">\n",
    "\n",
    "* 층의 개수\n",
    "* 은닉 유닛의 개수\n",
    "* 학습률\n",
    "* 활성화 함수\n",
    "* $\\cdots$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "응용 분야 : NLP(자연어처리), Vision, Speech, Structured data (광고, 검색, 보안, 물류 ... )\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "\n",
    "### 훈련/개발/테스트(train/dev/test) 세트\n",
    "<br>\n",
    "<img src=\"./images/train_dev_test_sets.png\" width=\"500\">\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<hr>\n",
    "\n",
    "#### 일치하지 않는 훈련/테스트 분포\n",
    "\n",
    "<table border=0 >\n",
    "    <tr>\n",
    "        <td> 훈련 세트 : <br>\n",
    "웹 페이지의 고양이 사진</td>\n",
    "        <td>&nbsp;&nbsp; <==> &nbsp;&nbsp;</td>        \n",
    "        <td> 개발/테스트 세트 : <br>\n",
    "앱을 사용하는 사용자들의 고양이 사진</td>\n",
    "    </tr>\n",
    "    </table>\n",
    "    \n",
    "    \n",
    "<br><br><br>\n",
    "\n",
    "*  dev 및 test가 동일한 분포에서 나왔는지 확인이 필요함.\n",
    "\n",
    "<br>\n",
    "\n",
    "*  테스트 세트가 없어도 괜찮을 수 있습니다. (즉, 단지 개발 세트만)\n",
    "<br><br><br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편향(Bias)/편차(Variance)\n",
    "\n",
    "<img src=\"./images/bias_variance_01.png\" width=\"500\" style=\"display:none\">\n",
    "\n",
    "<img src=\"./images/bias_variance.png\" width=\"500\">\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "\n",
    "### 편향(Bias)/편차(Variance)\n",
    "\n",
    "<br>\n",
    "<img src=\"./images/bias_variance_02.png\" width=\"500\" style=\"display:none\">\n",
    "\n",
    "<img src=\"./images/bias_variance_2.png\" width=\"500\">\n",
    "\n",
    "\n",
    "### 큰 편향과 큰 편차\n",
    "\n",
    "<br>\n",
    "<img src=\"./images/bias_variance_03.png\" width=\"300\" style=\"display:none\">\n",
    "\n",
    "<img src=\"./images/high_bias_variance.png\" width=\"400\">\n",
    "\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기계 학습을 위한 기본 \"레시피\"\n",
    "\n",
    "\n",
    "<img src=\"./images/ML_recipe.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화(Regularization) :  로지스틱 회귀\n",
    "\n",
    "<img src=\"./images/Regularization_Logistic_regression.PNG\" width=\"700\">\n",
    "\n",
    "<hr>\n",
    "\n",
    "### 정규화(Regularization) : 신경망\n",
    "\n",
    "<img src=\"./images/Regularization_Neural_Network.PNG\" width=\"700\">\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화가 과적합을 줄이는 이유\n",
    "\n",
    "<img src=\"./images/regularization_0.png\" width=\"600\"  style=\"display:none\">\n",
    "<img src=\"./images/Why_regularization_01.PNG\" width=\"600\">\n",
    "<hr>\n",
    "\n",
    "### 정규화는 과적합을 어떻게 방지하는가?\n",
    "<img src=\"./images/Why_regularization_02.PNG\" width=\"600\"><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 드롭아웃 정규화(Dropout regularazation)\n",
    "<br><br>\n",
    "<img src=\"./images/dropout-01.png\" width=700>\n",
    "<br><br><br><br><br><hr>\n",
    "\n",
    "### 드롭아웃 구현(\"Inverted dropout\")\n",
    "<img src=\"./images/Inverted_dropout_01.PNG\" width=700>\n",
    "\n",
    "<br><hr>\n",
    "\n",
    "### 테스트 시에 예측 적용 방법\n",
    "\n",
    "<img src=\"./images/Inverted_dropout_02.PNG\" width=700>\n",
    "<br><hr>\n",
    "\n",
    "### 드롭아웃 이해하기 :  왜 동작하는가?\n",
    "직관: 하나의 특징에만 의존 할 수 없으므로, 가중치를 분산해야 합니다.\n",
    "<img src=\"./images/dropout04.png\" width=700 style=\"display:none\">\n",
    "<img src=\"./images/Why_dropout_work.png\" width=\"700\">\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다른 정규화 방법 : 자료 증강 (data augmentation)\n",
    "<br><br>\n",
    "<img src=\"./images/data_augmentation.png\" width=700>\n",
    "<br><br><hr>\n",
    "\n",
    "\n",
    "### 다른 정규화 방법 : 조기 중단 (early stopping)\n",
    "<img src=\"./images/early_stopping.png\" width=700 style=\"display:none\">\n",
    "\n",
    "<img src=\"./images/Early_stopping_02.PNG\" width=700>\n",
    "<br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력 정규화: 훈련세트 정규화(normalization)\n",
    "\n",
    "<img src=\"./images/normalizing.png\" width=700 style=\"display:none\">\n",
    "<img src=\"./images/normalizing-1.png\" width=700>\n",
    "<br><br>\n",
    "<br><br>\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "### 입력을 정규화하는 이유\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"./images/why_normalize.png\" width=650 style=\"display:none\">\n",
    "<img src=\"./images/why_normalize-1.png\" width=650 style=\"display:none\">\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 소멸하는/폭발하는 (vanishing/exploding) 그레디언트\n",
    "<br>\n",
    "<img src=\"./images/vanishing_gradients.png\" width=700 style=\"display:none\">\n",
    "<img src=\"./images/vanishing_gradients-1.png\" width=700>\n",
    "\n",
    "<hr>\n",
    "\n",
    "### 심층신경망 가중치 초기화 : 단일 뉴런 예\n",
    "<br>\n",
    "<img src=\"./images/single_neuron_ex.png\" width=700 style=\"display:none\">\n",
    "<img src=\"./images/single_neuron_ex-1.png\" width=700>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래디언트의 수치 근사 : 미분 계산 점검\n",
    "<img src=\"./images/gradient_check.png\" width=700 style=\"display:none\">\n",
    "<img src=\"./images/gradient_check-2.png\" width=700 >\n",
    "\n",
    "<hr>\n",
    "\n",
    "### 그래디언트 점검\n",
    "<br><br>\n",
    "<br>\n",
    "$W^{[1]}, b^{[1]}, \\cdots , W^{[L]}, b^{[L]}$ 를 취해서 하나의 큰 벡터 $\\theta$ 로 모양을 바꾼다. \n",
    "<br>\n",
    "<br>\n",
    "<br><br>\n",
    "<br>\n",
    "$dW^{[1]}, db^{[1]}, \\cdots , dW^{[L]}, db^{[L]}$ 를 취해서 하나의 큰 벡터 $d\\theta$ 로 모양을 바꾼다. \n",
    "<br>\n",
    "<br>\n",
    "<br><br>\n",
    "<br><br>\n",
    "<br><br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그라디언트 점검 (Grad check)\n",
    "<img src=\"./images/gradient_check-3.png\" width=700 >\n",
    "<hr>\n",
    "\n",
    "### 그라디언트 검사 구현 노트\n",
    "<br>\n",
    "\n",
    "* 훈련 중에 사용하지 말고 - 디버그에만 사용\n",
    "\n",
    "<br>\n",
    "\n",
    "* 알고리즘이 그라디언트 검사에 실패하면, 구성 요소를 살펴보고 버그를 확인합니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "* 정규화를 기억하십시오.\n",
    "\n",
    "<br>\n",
    "\n",
    "* 드롭아웃과는 동작하지 않습니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "* 무작위 초기화에서 실행; 아마도 훈련 후에 다시.\n",
    "\n",
    "<hr>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
