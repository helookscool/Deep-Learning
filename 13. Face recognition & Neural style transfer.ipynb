{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"520\" height=\"280\" src=\"https://www.youtube.com/embed/wr4rx0Spihs?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"520\" height=\"280\" src=\"https://www.youtube.com/embed/wr4rx0Spihs?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼굴 인증(verification) vs. 얼굴 인식(recognition)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 인증/검증(verification)\n",
    "\n",
    "* 입력 이미지 & 이름/ID\n",
    "* 입력 이미지가 주장되는 사람 인지/아닌지 를 출력\n",
    "\n",
    "\n",
    "### 인식(recognition)\n",
    "\n",
    "* K 명의 데이터베이스 보유\n",
    "* 입력 이미지 가져 오기\n",
    "* 이미지가 K 인 중 한명인지 (또는 \"인식되지 않음\")\n",
    "\n",
    "<br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face recognition : One-shot learning\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/C4M4.01.PNG\" width=\"700\" >\n",
    "\n",
    "<br><br><hr>\n",
    "## \"유사도(Similarity)\" 함수 학습하기\n",
    "\n",
    "<img src=\"./images/C4M4.02.PNG\" width=\"700\" >\n",
    "\n",
    "<br><br><br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face recognition : Siamese network\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/C4M4.03.PNG\" width=\"700\" >\n",
    "\n",
    "<br><br><hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/C4M4.04.PNG\" width=\"700\" >\n",
    "\n",
    "<br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face recognition : 삼중 손실(Triplet loss) : 학습 목적\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/C4M4.05.PNG\" width=\"700\" style=\"display:none\">\n",
    "<img src=\"./images/C4M4.05.org.PNG\" width=\"700\" >\n",
    "\n",
    "\n",
    "<br><br><hr>\n",
    "\n",
    "## 손실함수(Loss function)\n",
    "\n",
    "<img src=\"./images/C4M4.06.org.PNG\" width=\"700\" >\n",
    "\n",
    "<br><br><hr>\n",
    "## 삼중항(triplets) A, P, N 선택하기\n",
    "\n",
    "<img src=\"./images/C4M4.07.org.PNG\" width=\"700\" >\n",
    "\n",
    "<br><br><hr>\n",
    "\n",
    "## 삼중한 손실을 사용한 훈련자료\n",
    "\n",
    "<br>\n",
    "<img src=\"./images/C4M4.08.PNG\" width=\"700\" style=\"display:none\">\n",
    "<img src=\"./images/C4M4.08.org.PNG\" width=\"700\" >\n",
    "\n",
    "\n",
    "<br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼굴 인증 및 이진 분류 : 유사도 함수 학습\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/C4M4.09.PNG\" width=\"700\" style=\"display:none\">\n",
    "<img src=\"./images/C4M4.09.org.png\" width=\"700\" >\n",
    "\n",
    "\n",
    "<br><br><hr>\n",
    "\n",
    "## 얼굴 인증 지도 학습\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/C4M4.10.PNG\" width=\"700\">\n",
    "\n",
    "<br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 스타일 전이 (Neural Style Transfer)\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/C4M4.11.PNG\" width=\"700\">\n",
    "\n",
    "<br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 심층 ConvNets 은 무엇을 학습하는가?\n",
    "\n",
    "### 심층신경망이 학습하는 것을 시각화하기\n",
    "\n",
    "\n",
    "<img src=\"./images/C4M4.12.PNG\" width=\"700\" style=\"display:none\">\n",
    "<img src=\"./images/C4M4.12.small.png\" width=\"700\" style=\"display:none\">\n",
    "<img src=\"./images/C4M4.12.org.PNG\" width=\"700\" >\n",
    "\n",
    "<br><br><hr>\n",
    "\n",
    "### 심층신경망 시각화 \n",
    "\n",
    "\n",
    "<img src=\"./images/C4M4.13.PNG\" width=\"700\">\n",
    "\n",
    "<br><br><hr>\n",
    "\n",
    "### 심층신경망 시각화 1층\n",
    "\n",
    "\n",
    "<img src=\"./images/C4M4.14.PNG\" width=\"700\">\n",
    "\n",
    "<br><br><hr>\n",
    "\n",
    "### 심층신경망 시각화  2층\n",
    "\n",
    "\n",
    "<img src=\"./images/C4M4.15.PNG\" width=\"700\">\n",
    "\n",
    "<br><br><hr>\n",
    "\n",
    "\n",
    "### 심층신경망 시각화 3층\n",
    "\n",
    "\n",
    "<img src=\"./images/C4M4.17.PNG\" width=\"700\">\n",
    "\n",
    "<br><br><hr>\n",
    "\n",
    "### 심층신경망 시각화 4층\n",
    "\n",
    "\n",
    "<img src=\"./images/C4M4.18.PNG\" width=\"700\">\n",
    "\n",
    "<br><br><hr>\n",
    "\n",
    "### 심층신경망 시각화 5층\n",
    "\n",
    "\n",
    "<img src=\"./images/C4M4.19.PNG\" width=\"700\">\n",
    "\n",
    "<br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 스타일 전이 (Neural Style Transfer) : 비용 함수\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/C4M4.20.PNG\" width=\"700\" style=\"display:none\">\n",
    "<img src=\"./images/C4M4.20.org.PNG\" width=\"700\" >\n",
    "\n",
    "<br><br><hr>\n",
    "\n",
    "## 생성된 이미지 G 찾기\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/C4M4.21.PNG\" width=\"700\" style=\"display:none\">\n",
    "<img src=\"./images/C4M4.21.org.PNG\" width=\"700\" >\n",
    "\n",
    "\n",
    "<br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 스타일 전이 : 내용(content) 비용 함수\n",
    "\n",
    "## $$ J(G) = \\alpha J_{content} (C, G) + \\beta J_{style} (S, G) $$\n",
    "\n",
    "### 은닉층 $l$ 을 사용하여 콘텐츠 비용을 계산한다고 가정해 보겠습니다.\n",
    "\n",
    "### 사전 훈련된 ConvNet 을 사용합니다. (예: VGG 네트워크)\n",
    "\n",
    "### $a^{[l](C)}$ 와 $a^{[l](G)}$를 이미지들에 대한 $l$층의 활성화라고 합시다.\n",
    "\n",
    "###  $a^{[l](C)}$ 와 $a^{[l](G)}$가 유사하면, 두 이미지는 유사한 콘텐츠를 가집니다.\n",
    "\n",
    "<br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 스타일 전이 : 스타일(Style) 비용 함수\n",
    "\n",
    "### 이미지에서 \"스타일\"의 의미\n",
    "\n",
    "<br>\n",
    "<img src=\"./images/C4M4.22-1.PNG\" width=\"700\" style=\"display:none\">\n",
    "<br>\n",
    "\"스타일\"을 측정하기 위해 $l$ 층의 활성화를 사용한다고 가정해 보겠습니다.<br>\n",
    "채널 간 활성화 사이의 상관 관계로 스타일을 정의합니다.\n",
    "<br>\n",
    "<img src=\"./images/C4M4.22-2.PNG\" width=\"200\" align=\"left\" >\n",
    "<br> <br> <br> 서로 다른 채널들 간의 활성화는 얼마나 상관 관계가 있습니까?\n",
    " <br>  <br> \n",
    "<br><br><hr>\n",
    "\n",
    "## 이미지의 스타일에 대한 직관\n",
    "<br>\n",
    "<img src=\"./images/C4M4.23.PNG\" width=\"700\" >\n",
    "<br>\n",
    "\n",
    "<br><br><hr>\n",
    "\n",
    "## 스타일 행렬\n",
    "<img src=\"./images/C4M4.24.org.PNG\" width=\"700\" >\n",
    "<br><br><hr>\n",
    "\n",
    "## 스타일 비용 함수\n",
    "<br>\n",
    "<img src=\"./images/C4M4.25.org.PNG\" width=\"700\" >\n",
    "<br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 모델 일반화 1D & 3D : Convolution in 2D & 1D\n",
    "<br>\n",
    "<img src=\"./images/C4M4.26.PNG\" width=\"700\">\n",
    "\n",
    "<br>\n",
    "\n",
    "<br><br><hr>\n",
    "\n",
    "## 3D Data\n",
    "<br>\n",
    "<img src=\"./images/3D_data.gif\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "<br><br><hr>\n",
    "## 3D Convolution\n",
    "<br>\n",
    "<img src=\"./images/C4M4.27.PNG\" width=\"700\">\n",
    "\n",
    "<br>\n",
    "\n",
    "<br><br><hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
